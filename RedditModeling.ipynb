{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bagofWords = []\n",
    "for x in range(1,201):\n",
    "    bagofWords.append(str(x)+\"_bagOfWords_Post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_headers = [\"mean_totalcommentsBefore_Source\", \"std_totalcommentsBefore_Source\", \"min_totalcommentsBefore_Source\", \"max_totalcommentsBefore_Source\", \"median_totalcommentsBefore_Source\", \"mean_comments24Before_Source\", \"std_comments24Before_Source\", \"min_comments24Before_Source\", \"max_comments24Before_Source\", \"median_comments24Before_Source\", \n",
    "               \"mean_commentsIntervalBefore_Source\", \"std_commentsIntervalBefore_Source\", \"min_commentsIntervalBefore_Source\", \"max_commentsIntervalBefore_Source\", \"median_commentsIntervalBefore_Source\", \"mean_comments24After_Source\", \"std_comments24After_Source\", \"min_comments24After_Source\", \"max_comments24After_Source\", \"median_comments24After_Source\",\n",
    "               \"mean_comments24Interval_Source\", \"std_comments24Interval_Source\", \"min_comments24Interval_Source\", \"max_comments24Interval_Source\", \"median_comments24Interval_Source\", \"mean_totallinksBefore_Source\", \"std_totallinksBefore_Source\", \"min_totallinksBefore_Source\", \"max_totallinksBefore_Source\", \"median_totallinksBefore_Source\", \"mean_links24Before_Source\", \n",
    "               \"std_links24Before_Source\", \"min_links24Before_Source\", \"max_links24Before_Source\", \"median_links24Before_Source\", \"mean_linksIntervalBefore_Source\", \"std_linksIntervalBefore_Source\", \"min_linksIntervalBefore_Source\", \"max_linksIntervalBefore_Source\", \"median_linksIntervalBefore_Source\", \"mean_links24After_Source\", \"std_links24After_Source\", \n",
    "               \"min_links24After_Source\", \"max_links24After_Source\", \"median_links24After_Source\",\"mean_links24Interval_Source\", \"std_links24Interval_Source\", \"min_links24Interval_Source\", \"max_links24Interval_Source\", \"median_link24Interval_Source\", \"totalcommentsBefore_Post\", \"comments24Before_Post\", \"commentsIntervalBefore_Post\", \"comments24After_Post\",\n",
    "               \"comments24Interval_Post\",\"totallinksBefore_Post\", \"links24Before_Post\", \"linksIntervalBefore_Post\", \"links24After_Post\",\"links24Interval_Post\", \"timeIntervalPub_Post\", \"Length_Post\", \"1_bagOfWords_Post\", \"2_bagOfWords_Post\", \"3_bagOfWords_Post\", \"4_bagOfWords_Post\", \"5_bagOfWords_Post\", \"6_bagOfWords_Post\",\"7_bagOfWords_Post\",'8_bagOfWords_Post',\n",
    "               '9_bagOfWords_Post','10_bagOfWords_Post','11_bagOfWords_Post','12_bagOfWords_Post','13_bagOfWords_Post','14_bagOfWords_Post','15_bagOfWords_Post','16_bagOfWords_Post','17_bagOfWords_Post','18_bagOfWords_Post','19_bagOfWords_Post','20_bagOfWords_Post','21_bagOfWords_Post','22_bagOfWords_Post','23_bagOfWords_Post','24_bagOfWords_Post',\n",
    "               '25_bagOfWords_Post','26_bagOfWords_Post','27_bagOfWords_Post','28_bagOfWords_Post','29_bagOfWords_Post','30_bagOfWords_Post','31_bagOfWords_Post','32_bagOfWords_Post','33_bagOfWords_Post','34_bagOfWords_Post','35_bagOfWords_Post','36_bagOfWords_Post','37_bagOfWords_Post','38_bagOfWords_Post','39_bagOfWords_Post','40_bagOfWords_Post',\n",
    "               '41_bagOfWords_Post','42_bagOfWords_Post','43_bagOfWords_Post','44_bagOfWords_Post','45_bagOfWords_Post','46_bagOfWords_Post','47_bagOfWords_Post','48_bagOfWords_Post','49_bagOfWords_Post','50_bagOfWords_Post','51_bagOfWords_Post','52_bagOfWords_Post','53_bagOfWords_Post','54_bagOfWords_Post','55_bagOfWords_Post','56_bagOfWords_Post',\n",
    "               '57_bagOfWords_Post','58_bagOfWords_Post','59_bagOfWords_Post','60_bagOfWords_Post','61_bagOfWords_Post','62_bagOfWords_Post','63_bagOfWords_Post','64_bagOfWords_Post','65_bagOfWords_Post','66_bagOfWords_Post','67_bagOfWords_Post','68_bagOfWords_Post','69_bagOfWords_Post','70_bagOfWords_Post','71_bagOfWords_Post','72_bagOfWords_Post',\n",
    "               '73_bagOfWords_Post','74_bagOfWords_Post','75_bagOfWords_Post','76_bagOfWords_Post','77_bagOfWords_Post','78_bagOfWords_Post','79_bagOfWords_Post','80_bagOfWords_Post','81_bagOfWords_Post','82_bagOfWords_Post','83_bagOfWords_Post','84_bagOfWords_Post','85_bagOfWords_Post','86_bagOfWords_Post','87_bagOfWords_Post','88_bagOfWords_Post',\n",
    "               '89_bagOfWords_Post','90_bagOfWords_Post','91_bagOfWords_Post','92_bagOfWords_Post','93_bagOfWords_Post','94_bagOfWords_Post','95_bagOfWords_Post','96_bagOfWords_Post','97_bagOfWords_Post','98_bagOfWords_Post','99_bagOfWords_Post','100_bagOfWords_Post','101_bagOfWords_Post','102_bagOfWords_Post','103_bagOfWords_Post','104_bagOfWords_Post',\n",
    "               '105_bagOfWords_Post','106_bagOfWords_Post','107_bagOfWords_Post','108_bagOfWords_Post','109_bagOfWords_Post','110_bagOfWords_Post','111_bagOfWords_Post','112_bagOfWords_Post','113_bagOfWords_Post','114_bagOfWords_Post','115_bagOfWords_Post','116_bagOfWords_Post','117_bagOfWords_Post','118_bagOfWords_Post','119_bagOfWords_Post','120_bagOfWords_Post',\n",
    "               '121_bagOfWords_Post','122_bagOfWords_Post','123_bagOfWords_Post','124_bagOfWords_Post','125_bagOfWords_Post','126_bagOfWords_Post','127_bagOfWords_Post','128_bagOfWords_Post','129_bagOfWords_Post','130_bagOfWords_Post','131_bagOfWords_Post','132_bagOfWords_Post','133_bagOfWords_Post','134_bagOfWords_Post','135_bagOfWords_Post','136_bagOfWords_Post',\n",
    "               '137_bagOfWords_Post','138_bagOfWords_Post','139_bagOfWords_Post','140_bagOfWords_Post','141_bagOfWords_Post','142_bagOfWords_Post','143_bagOfWords_Post','144_bagOfWords_Post','145_bagOfWords_Post','146_bagOfWords_Post','147_bagOfWords_Post','148_bagOfWords_Post','149_bagOfWords_Post','150_bagOfWords_Post','151_bagOfWords_Post','152_bagOfWords_Post',\n",
    "               '153_bagOfWords_Post','154_bagOfWords_Post','155_bagOfWords_Post','156_bagOfWords_Post','157_bagOfWords_Post','158_bagOfWords_Post','159_bagOfWords_Post','160_bagOfWords_Post','161_bagOfWords_Post','162_bagOfWords_Post','163_bagOfWords_Post','164_bagOfWords_Post','165_bagOfWords_Post','166_bagOfWords_Post','167_bagOfWords_Post','168_bagOfWords_Post',\n",
    "               '169_bagOfWords_Post','170_bagOfWords_Post','171_bagOfWords_Post','172_bagOfWords_Post','173_bagOfWords_Post','174_bagOfWords_Post','175_bagOfWords_Post','176_bagOfWords_Post','177_bagOfWords_Post','178_bagOfWords_Post','179_bagOfWords_Post','180_bagOfWords_Post','181_bagOfWords_Post','182_bagOfWords_Post','183_bagOfWords_Post','184_bagOfWords_Post',\n",
    "               '185_bagOfWords_Post','186_bagOfWords_Post','187_bagOfWords_Post','188_bagOfWords_Post','189_bagOfWords_Post','190_bagOfWords_Post','191_bagOfWords_Post','192_bagOfWords_Post','193_bagOfWords_Post','194_bagOfWords_Post','195_bagOfWords_Post','196_bagOfWords_Post','197_bagOfWords_Post','198_bagOfWords_Post','199_bagOfWords_Post','200_bagOfWords_Post',\n",
    "               \"monday_Basetime\", \"tuesday_Basetime\", \"wednesday_Basetime\", \"thursday_Basetime\", \"friday_Basetime\", \"saturday_Basetime\", \"sunday_Basetime\", \"monday_Post\", \"tuesday_Post\", \"wednesday_Post\", \"thursday_Post\", \"friday_Post\", \"saturday_Post\", \"sunday_Post\", \"totalParentPages_Post\",\"min_comments_Parent\", \"max_comments_Parent\", \"mean_comments_Parent\",\n",
    "               \"totalComments\"]\n",
    "blog_data = pd.read_csv('BlogFeedback/blogData_train.csv',names=col_headers, na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52397, 281)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_totalcommentsBefore_Source</th>\n",
       "      <th>std_totalcommentsBefore_Source</th>\n",
       "      <th>min_totalcommentsBefore_Source</th>\n",
       "      <th>max_totalcommentsBefore_Source</th>\n",
       "      <th>median_totalcommentsBefore_Source</th>\n",
       "      <th>mean_comments24Before_Source</th>\n",
       "      <th>std_comments24Before_Source</th>\n",
       "      <th>min_comments24Before_Source</th>\n",
       "      <th>max_comments24Before_Source</th>\n",
       "      <th>median_comments24Before_Source</th>\n",
       "      <th>...</th>\n",
       "      <th>sunday_Basetime</th>\n",
       "      <th>monday_Post</th>\n",
       "      <th>tuesday_Post</th>\n",
       "      <th>wednesday_Post</th>\n",
       "      <th>thursday_Post</th>\n",
       "      <th>friday_Post</th>\n",
       "      <th>saturday_Post</th>\n",
       "      <th>sunday_Post</th>\n",
       "      <th>Length_Post</th>\n",
       "      <th>totalComments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2508</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11668</td>\n",
       "      <td>2203</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2664</td>\n",
       "      <td>5296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3239</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8821</td>\n",
       "      <td>2783</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>2725.189535</td>\n",
       "      <td>169.0</td>\n",
       "      <td>4023.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3266</td>\n",
       "      <td>6209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>267</td>\n",
       "      <td>4307</td>\n",
       "      <td>1988</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5437</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2991</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11668</td>\n",
       "      <td>2659</td>\n",
       "      <td>1387.5</td>\n",
       "      <td>1039.278436</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4554</td>\n",
       "      <td>2769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2945</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7869</td>\n",
       "      <td>2689</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_totalcommentsBefore_Source  std_totalcommentsBefore_Source  \\\n",
       "0                             2508                          1642.0   \n",
       "1                             3239                          2105.0   \n",
       "2                             1979                          1331.0   \n",
       "3                             2991                          1975.0   \n",
       "4                             2945                          2046.0   \n",
       "\n",
       "   min_totalcommentsBefore_Source  max_totalcommentsBefore_Source  \\\n",
       "0                               1                           11668   \n",
       "1                               2                            8821   \n",
       "2                             267                            4307   \n",
       "3                               2                           11668   \n",
       "4                               2                            7869   \n",
       "\n",
       "   median_totalcommentsBefore_Source  mean_comments24Before_Source  \\\n",
       "0                               2203                        2546.0   \n",
       "1                               2783                        2096.0   \n",
       "2                               1988                         611.0   \n",
       "3                               2659                        1387.5   \n",
       "4                               2689                        2546.0   \n",
       "\n",
       "   std_comments24Before_Source  min_comments24Before_Source  \\\n",
       "0                  1074.000000                       2307.0   \n",
       "1                  2725.189535                        169.0   \n",
       "2                  1074.000000                        611.0   \n",
       "3                  1039.278436                        445.0   \n",
       "4                  1074.000000                       2307.0   \n",
       "\n",
       "   max_comments24Before_Source  median_comments24Before_Source  ...  \\\n",
       "0                       2784.0                          2550.0  ...   \n",
       "1                       4023.0                          2096.0  ...   \n",
       "2                        611.0                           611.0  ...   \n",
       "3                       2739.0                          1183.0  ...   \n",
       "4                       2784.0                          2550.0  ...   \n",
       "\n",
       "   sunday_Basetime  monday_Post  tuesday_Post  wednesday_Post  thursday_Post  \\\n",
       "0                0            0             0               0              0   \n",
       "1                0            0             0               0              0   \n",
       "2                0            1             0               0              0   \n",
       "3                0            0             1               0              0   \n",
       "4                0            1             0               0              0   \n",
       "\n",
       "   friday_Post  saturday_Post  sunday_Post  Length_Post  totalComments  \n",
       "0            0              1            0         2664           5296  \n",
       "1            1              0            0         3266           6209  \n",
       "2            0              0            0         5437           1988  \n",
       "3            0              0            0         4554           2769  \n",
       "4            0              0            0         1142              2  \n",
       "\n",
       "[5 rows x 241 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df = pd.read_csv('reddit-final.csv')\n",
    "reddit_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_names = reddit_df.isnull().any()\n",
    "nullcols = list(na_names.where(na_names == True).dropna().index)\n",
    "nullcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix_r = reddit_df.iloc[:, :-1]\n",
    "Y_matrix_r = reddit_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match blog data with reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_List = reddit_df.columns\n",
    "blog_data = blog_data[col_List] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix_reddit = blog_data.iloc[:, :-1]\n",
    "Y_matrix_reddit = blog_data.iloc[:,-1]\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_matrix_reddit, Y_matrix, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 949.67\n",
      "Variance score: 0.25\n",
      "Root-mean squared error: 30.82\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train_r, y_train_r)\n",
    "lmPred = lm.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % lm.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, lmPred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear base model on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1722660232757909760.00\n",
      "Variance score: -688294198747.43\n",
      "Root-mean squared error: 1312501517.24\n"
     ]
    }
   ],
   "source": [
    "lmPred_r = lm.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % lm.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, lmPred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 991.70\n",
      "Variance score: 0.22\n",
      "Root-mean squared error: 31.49\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsRegressor(n_neighbors=15, weights='uniform') \n",
    "KNN.fit(X_train_r, y_train_r)\n",
    "KNN_pred = KNN.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((KNN.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, KNN_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN base model on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8514082.89\n",
      "Variance score: -2.40\n",
      "Root-mean squared error: 1312501517.24\n"
     ]
    }
   ],
   "source": [
    "KNNPred_r = KNN.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((KNN.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, lmPred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 890.51\n",
      "Variance score: 0.30\n",
      "Root-mean squared error: 29.84\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train_r, y_train_r)\n",
    "xgb_Pred = xgb.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((xgb.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, xgb_Pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost base model on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8563686.05\n",
      "Variance score: -2.42\n",
      "Root-mean squared error: 2926.38\n"
     ]
    }
   ],
   "source": [
    "xgb_Pred_r = xgb.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((xgb.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, xgb_Pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 975.02\n",
      "Variance score: 0.24\n",
      "Root-mean squared error: 31.23\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor() \n",
    "rf_reg.fit(X_train_r, y_train_r)\n",
    "rf_reg_pred = rf_reg.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((rf_reg.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, rf_reg_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest base model on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 7869436.71\n",
      "Variance score: -2.14\n",
      "Root-mean squared error: 2805.25\n"
     ]
    }
   ],
   "source": [
    "rf_reg_pred_r = rf_reg.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((rf_reg.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, rf_reg_pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1949.21\n",
      "Variance score: -0.53\n",
      "Root-mean squared error: 44.15\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor() \n",
    "dt.fit(X_train_r, y_train_r)\n",
    "dt_pred = dt.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((dt.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % dt.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, dt_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decison Tree base model on Reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8867992.55\n",
      "Variance score: -2.54\n",
      "Root-mean squared error: 2977.92\n"
     ]
    }
   ],
   "source": [
    "dt_pred_r = dt.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((dt.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % dt.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, dt_pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 910.12\n",
      "Variance score: 0.29\n",
      "Root-mean squared error: 30.17\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train_r, y_train_r)\n",
    "gb_pred = gb.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((gb.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % gb.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, gb_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting base model on Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8518621.55\n",
      "Variance score: -2.40\n",
      "Root-mean squared error: 2918.67\n"
     ]
    }
   ],
   "source": [
    "gb_pred_r = gb.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((gb.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % gb.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, gb_pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_test_r)\n",
    "X_test_scaled_r = scaler.transform(X_test_r)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_r)\n",
    "X_train_scaled_r = scaler.transform(X_train_r)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_matrix_r)\n",
    "X_matrix_scaled_r = scaler.transform(X_matrix_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 37693214271276023457775616.00\n",
      "Variance score: -29571158486639567699968.00\n",
      "Root-mean squared error: 6139479967495.29\n"
     ]
    }
   ],
   "source": [
    "lm_scaled = LinearRegression()\n",
    "lm_scaled.fit(X_train_scaled_r, y_train_r)\n",
    "lmPred_scaled = lm_scaled.predict(X_test_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm_scaled.predict(X_test_scaled_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % lm_scaled.score(X_test_scaled_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, lmPred_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 3587051017303214587815919616.00\n",
      "Variance score: -1433217275743215026176.00\n",
      "Root-mean squared error: 59891994601141.93\n"
     ]
    }
   ],
   "source": [
    "lmPred_scaled_r = lm_scaled.predict(X_matrix_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm_scaled.predict(X_matrix_scaled_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % lm_scaled.score(X_matrix_scaled_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, lmPred_scaled_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1319.67\n",
      "Variance score: -0.04\n",
      "Root-mean squared error: 30.86\n"
     ]
    }
   ],
   "source": [
    "KNN_scaled = KNeighborsRegressor(n_neighbors=15, weights='uniform') \n",
    "KNN_scaled.fit(X_train_scaled_r, y_train_r)\n",
    "KNN_scaled_pred = KNN_scaled.predict(X_test_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((KNN.predict(X_test_scaled_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN.score(X_test_scaled_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, KNN_scaled_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 9183204.66\n",
      "Variance score: -2.67\n",
      "Root-mean squared error: 3030.38\n"
     ]
    }
   ],
   "source": [
    "KNN_scaled_Pred_r = KNN_scaled.predict(X_matrix_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((KNN_scaled.predict(X_matrix_scaled_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN_scaled.score(X_matrix_scaled_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, KNN_scaled_Pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 879.03\n",
      "Variance score: 0.31\n",
      "Root-mean squared error: 29.65\n"
     ]
    }
   ],
   "source": [
    "xgb_scaled = XGBRegressor()\n",
    "xgb_scaled.fit(X_train_scaled_r, y_train_r)\n",
    "xgb_Pred_scaled = xgb_scaled.predict(X_test_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((xgb_scaled.predict(X_test_scaled_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb_scaled.score(X_test_scaled_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, xgb_Pred_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 9114054.68\n",
      "Variance score: -2.64\n",
      "Root-mean squared error: 3018.95\n"
     ]
    }
   ],
   "source": [
    "xgb_Pred_r_scaled = xgb_scaled.predict(X_matrix_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((xgb_scaled.predict(X_matrix_scaled_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb_scaled.score(X_matrix_scaled_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, xgb_Pred_r_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 945.18\n",
      "Variance score: 0.26\n",
      "Root-mean squared error: 30.74\n"
     ]
    }
   ],
   "source": [
    "rf_reg_scaled = RandomForestRegressor() \n",
    "rf_reg_scaled.fit(X_train_scaled_r, y_train_r)\n",
    "rf_reg_pred_scaled = rf_reg_scaled.predict(X_test_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((rf_reg_scaled.predict(X_test_scaled_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg_scaled.score(X_test_scaled_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, rf_reg_pred_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 9123119.47\n",
      "Variance score: -2.65\n",
      "Root-mean squared error: 3020.45\n"
     ]
    }
   ],
   "source": [
    "rf_reg_pred_r_scaled = rf_reg_scaled.predict(X_matrix_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((rf_reg_scaled.predict(X_matrix_scaled_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg_scaled.score(X_matrix_scaled_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, rf_reg_pred_r_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1961.13\n",
      "Variance score: -0.54\n",
      "Root-mean squared error: 34.85\n"
     ]
    }
   ],
   "source": [
    "dt_scaled = DecisionTreeRegressor() \n",
    "dt_scaled.fit(X_train_scaled_r, y_train_r)\n",
    "dt_pred_scaled = dt.predict(X_test_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((dt_scaled.predict(X_test_scaled_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % dt_scaled.score(X_test_scaled_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, dt_pred_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 9132632.09\n",
      "Variance score: -2.65\n",
      "Root-mean squared error: 3022.02\n"
     ]
    }
   ],
   "source": [
    "dt_pred_r_scaled = dt_scaled.predict(X_matrix_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((dt_scaled.predict(X_matrix_scaled_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % dt_scaled.score(X_matrix_scaled_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, dt_pred_r_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 913.15\n",
      "Variance score: 0.28\n",
      "Root-mean squared error: 30.22\n"
     ]
    }
   ],
   "source": [
    "gb_scaled = GradientBoostingRegressor()\n",
    "gb_scaled.fit(X_train_scaled_r, y_train_r)\n",
    "gb_pred_scaled = gb_scaled.predict(X_test_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((gb_scaled.predict(X_test_scaled_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % gb_scaled.score(X_test_scaled_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, gb_pred_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 9142631.79\n",
      "Variance score: -2.65\n",
      "Root-mean squared error: 3023.68\n"
     ]
    }
   ],
   "source": [
    "gb_pred_r_scaled = gb_scaled.predict(X_matrix_scaled_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((gb_scaled.predict(X_matrix_scaled_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % gb_scaled.score(X_matrix_scaled_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, gb_pred_r_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix_base = X_matrix_reddit[[\"1_bagOfWords_Post\", \"2_bagOfWords_Post\", \"3_bagOfWords_Post\", \"4_bagOfWords_Post\", \n",
    "                       \"5_bagOfWords_Post\", \"6_bagOfWords_Post\",\"7_bagOfWords_Post\",'8_bagOfWords_Post',\n",
    "                       '9_bagOfWords_Post','10_bagOfWords_Post','11_bagOfWords_Post','12_bagOfWords_Post',\n",
    "                       '13_bagOfWords_Post','14_bagOfWords_Post','15_bagOfWords_Post','16_bagOfWords_Post',\n",
    "                       '17_bagOfWords_Post','18_bagOfWords_Post','19_bagOfWords_Post','20_bagOfWords_Post',\n",
    "                       '21_bagOfWords_Post','22_bagOfWords_Post','23_bagOfWords_Post','24_bagOfWords_Post',\n",
    "                       '25_bagOfWords_Post','26_bagOfWords_Post','27_bagOfWords_Post','28_bagOfWords_Post',\n",
    "                       '29_bagOfWords_Post','30_bagOfWords_Post','31_bagOfWords_Post','32_bagOfWords_Post',\n",
    "                       '33_bagOfWords_Post','34_bagOfWords_Post','35_bagOfWords_Post','36_bagOfWords_Post',\n",
    "                       '37_bagOfWords_Post','38_bagOfWords_Post','39_bagOfWords_Post','40_bagOfWords_Post',\n",
    "                       '41_bagOfWords_Post','42_bagOfWords_Post','43_bagOfWords_Post','44_bagOfWords_Post',\n",
    "                       '45_bagOfWords_Post','46_bagOfWords_Post','47_bagOfWords_Post','48_bagOfWords_Post',\n",
    "                       '49_bagOfWords_Post','50_bagOfWords_Post','51_bagOfWords_Post','52_bagOfWords_Post',\n",
    "                       '53_bagOfWords_Post','54_bagOfWords_Post','55_bagOfWords_Post','56_bagOfWords_Post',\n",
    "                       '57_bagOfWords_Post','58_bagOfWords_Post','59_bagOfWords_Post','60_bagOfWords_Post',\n",
    "                       '61_bagOfWords_Post','62_bagOfWords_Post','63_bagOfWords_Post','64_bagOfWords_Post',\n",
    "                       '65_bagOfWords_Post','66_bagOfWords_Post','67_bagOfWords_Post','68_bagOfWords_Post',\n",
    "                       '69_bagOfWords_Post','70_bagOfWords_Post','71_bagOfWords_Post','72_bagOfWords_Post',\n",
    "                       '73_bagOfWords_Post','74_bagOfWords_Post','75_bagOfWords_Post','76_bagOfWords_Post',\n",
    "                       '77_bagOfWords_Post','78_bagOfWords_Post','79_bagOfWords_Post','80_bagOfWords_Post',\n",
    "                       '81_bagOfWords_Post','82_bagOfWords_Post','83_bagOfWords_Post','84_bagOfWords_Post',\n",
    "                       '85_bagOfWords_Post','86_bagOfWords_Post','87_bagOfWords_Post','88_bagOfWords_Post',\n",
    "                       '89_bagOfWords_Post','90_bagOfWords_Post','91_bagOfWords_Post','92_bagOfWords_Post',\n",
    "                       '93_bagOfWords_Post','94_bagOfWords_Post','95_bagOfWords_Post','96_bagOfWords_Post',\n",
    "                       '97_bagOfWords_Post','98_bagOfWords_Post','99_bagOfWords_Post','100_bagOfWords_Post',\n",
    "                       '101_bagOfWords_Post','102_bagOfWords_Post','103_bagOfWords_Post','104_bagOfWords_Post',\n",
    "                       '105_bagOfWords_Post','106_bagOfWords_Post','107_bagOfWords_Post','108_bagOfWords_Post',\n",
    "                       '109_bagOfWords_Post','110_bagOfWords_Post','111_bagOfWords_Post','112_bagOfWords_Post',\n",
    "                       '113_bagOfWords_Post','114_bagOfWords_Post','115_bagOfWords_Post','116_bagOfWords_Post',\n",
    "                       '117_bagOfWords_Post','118_bagOfWords_Post','119_bagOfWords_Post','120_bagOfWords_Post',\n",
    "                       '121_bagOfWords_Post','122_bagOfWords_Post','123_bagOfWords_Post','124_bagOfWords_Post',\n",
    "                       '125_bagOfWords_Post','126_bagOfWords_Post','127_bagOfWords_Post','128_bagOfWords_Post',\n",
    "                       '129_bagOfWords_Post','130_bagOfWords_Post','131_bagOfWords_Post','132_bagOfWords_Post',\n",
    "                       '133_bagOfWords_Post','134_bagOfWords_Post','135_bagOfWords_Post','136_bagOfWords_Post',\n",
    "                       '137_bagOfWords_Post','138_bagOfWords_Post','139_bagOfWords_Post','140_bagOfWords_Post',\n",
    "                       '141_bagOfWords_Post','142_bagOfWords_Post','143_bagOfWords_Post','144_bagOfWords_Post',\n",
    "                       '145_bagOfWords_Post','146_bagOfWords_Post','147_bagOfWords_Post','148_bagOfWords_Post',\n",
    "                       '149_bagOfWords_Post','150_bagOfWords_Post','151_bagOfWords_Post','152_bagOfWords_Post',\n",
    "                       '153_bagOfWords_Post','154_bagOfWords_Post','155_bagOfWords_Post','156_bagOfWords_Post',\n",
    "                       '157_bagOfWords_Post','158_bagOfWords_Post','159_bagOfWords_Post','160_bagOfWords_Post',\n",
    "                       '161_bagOfWords_Post','162_bagOfWords_Post','163_bagOfWords_Post','164_bagOfWords_Post',\n",
    "                       '165_bagOfWords_Post','166_bagOfWords_Post','167_bagOfWords_Post','168_bagOfWords_Post',\n",
    "                       '169_bagOfWords_Post','170_bagOfWords_Post','171_bagOfWords_Post','172_bagOfWords_Post',\n",
    "                       '173_bagOfWords_Post','174_bagOfWords_Post','175_bagOfWords_Post','176_bagOfWords_Post',\n",
    "                       '177_bagOfWords_Post','178_bagOfWords_Post','179_bagOfWords_Post','180_bagOfWords_Post',\n",
    "                       '181_bagOfWords_Post','182_bagOfWords_Post','183_bagOfWords_Post','184_bagOfWords_Post',\n",
    "                       '185_bagOfWords_Post','186_bagOfWords_Post','187_bagOfWords_Post','188_bagOfWords_Post',\n",
    "                       '189_bagOfWords_Post','190_bagOfWords_Post','191_bagOfWords_Post','192_bagOfWords_Post',\n",
    "                       '193_bagOfWords_Post','194_bagOfWords_Post','195_bagOfWords_Post','196_bagOfWords_Post',\n",
    "                       '197_bagOfWords_Post','198_bagOfWords_Post','199_bagOfWords_Post','200_bagOfWords_Post',]]\n",
    "bow_matrix_r = X_matrix_r[[\"1_bagOfWords_Post\", \"2_bagOfWords_Post\", \"3_bagOfWords_Post\", \"4_bagOfWords_Post\", \n",
    "                       \"5_bagOfWords_Post\", \"6_bagOfWords_Post\",\"7_bagOfWords_Post\",'8_bagOfWords_Post',\n",
    "                       '9_bagOfWords_Post','10_bagOfWords_Post','11_bagOfWords_Post','12_bagOfWords_Post',\n",
    "                       '13_bagOfWords_Post','14_bagOfWords_Post','15_bagOfWords_Post','16_bagOfWords_Post',\n",
    "                       '17_bagOfWords_Post','18_bagOfWords_Post','19_bagOfWords_Post','20_bagOfWords_Post',\n",
    "                       '21_bagOfWords_Post','22_bagOfWords_Post','23_bagOfWords_Post','24_bagOfWords_Post',\n",
    "                       '25_bagOfWords_Post','26_bagOfWords_Post','27_bagOfWords_Post','28_bagOfWords_Post',\n",
    "                       '29_bagOfWords_Post','30_bagOfWords_Post','31_bagOfWords_Post','32_bagOfWords_Post',\n",
    "                       '33_bagOfWords_Post','34_bagOfWords_Post','35_bagOfWords_Post','36_bagOfWords_Post',\n",
    "                       '37_bagOfWords_Post','38_bagOfWords_Post','39_bagOfWords_Post','40_bagOfWords_Post',\n",
    "                       '41_bagOfWords_Post','42_bagOfWords_Post','43_bagOfWords_Post','44_bagOfWords_Post',\n",
    "                       '45_bagOfWords_Post','46_bagOfWords_Post','47_bagOfWords_Post','48_bagOfWords_Post',\n",
    "                       '49_bagOfWords_Post','50_bagOfWords_Post','51_bagOfWords_Post','52_bagOfWords_Post',\n",
    "                       '53_bagOfWords_Post','54_bagOfWords_Post','55_bagOfWords_Post','56_bagOfWords_Post',\n",
    "                       '57_bagOfWords_Post','58_bagOfWords_Post','59_bagOfWords_Post','60_bagOfWords_Post',\n",
    "                       '61_bagOfWords_Post','62_bagOfWords_Post','63_bagOfWords_Post','64_bagOfWords_Post',\n",
    "                       '65_bagOfWords_Post','66_bagOfWords_Post','67_bagOfWords_Post','68_bagOfWords_Post',\n",
    "                       '69_bagOfWords_Post','70_bagOfWords_Post','71_bagOfWords_Post','72_bagOfWords_Post',\n",
    "                       '73_bagOfWords_Post','74_bagOfWords_Post','75_bagOfWords_Post','76_bagOfWords_Post',\n",
    "                       '77_bagOfWords_Post','78_bagOfWords_Post','79_bagOfWords_Post','80_bagOfWords_Post',\n",
    "                       '81_bagOfWords_Post','82_bagOfWords_Post','83_bagOfWords_Post','84_bagOfWords_Post',\n",
    "                       '85_bagOfWords_Post','86_bagOfWords_Post','87_bagOfWords_Post','88_bagOfWords_Post',\n",
    "                       '89_bagOfWords_Post','90_bagOfWords_Post','91_bagOfWords_Post','92_bagOfWords_Post',\n",
    "                       '93_bagOfWords_Post','94_bagOfWords_Post','95_bagOfWords_Post','96_bagOfWords_Post',\n",
    "                       '97_bagOfWords_Post','98_bagOfWords_Post','99_bagOfWords_Post','100_bagOfWords_Post',\n",
    "                       '101_bagOfWords_Post','102_bagOfWords_Post','103_bagOfWords_Post','104_bagOfWords_Post',\n",
    "                       '105_bagOfWords_Post','106_bagOfWords_Post','107_bagOfWords_Post','108_bagOfWords_Post',\n",
    "                       '109_bagOfWords_Post','110_bagOfWords_Post','111_bagOfWords_Post','112_bagOfWords_Post',\n",
    "                       '113_bagOfWords_Post','114_bagOfWords_Post','115_bagOfWords_Post','116_bagOfWords_Post',\n",
    "                       '117_bagOfWords_Post','118_bagOfWords_Post','119_bagOfWords_Post','120_bagOfWords_Post',\n",
    "                       '121_bagOfWords_Post','122_bagOfWords_Post','123_bagOfWords_Post','124_bagOfWords_Post',\n",
    "                       '125_bagOfWords_Post','126_bagOfWords_Post','127_bagOfWords_Post','128_bagOfWords_Post',\n",
    "                       '129_bagOfWords_Post','130_bagOfWords_Post','131_bagOfWords_Post','132_bagOfWords_Post',\n",
    "                       '133_bagOfWords_Post','134_bagOfWords_Post','135_bagOfWords_Post','136_bagOfWords_Post',\n",
    "                       '137_bagOfWords_Post','138_bagOfWords_Post','139_bagOfWords_Post','140_bagOfWords_Post',\n",
    "                       '141_bagOfWords_Post','142_bagOfWords_Post','143_bagOfWords_Post','144_bagOfWords_Post',\n",
    "                       '145_bagOfWords_Post','146_bagOfWords_Post','147_bagOfWords_Post','148_bagOfWords_Post',\n",
    "                       '149_bagOfWords_Post','150_bagOfWords_Post','151_bagOfWords_Post','152_bagOfWords_Post',\n",
    "                       '153_bagOfWords_Post','154_bagOfWords_Post','155_bagOfWords_Post','156_bagOfWords_Post',\n",
    "                       '157_bagOfWords_Post','158_bagOfWords_Post','159_bagOfWords_Post','160_bagOfWords_Post',\n",
    "                       '161_bagOfWords_Post','162_bagOfWords_Post','163_bagOfWords_Post','164_bagOfWords_Post',\n",
    "                       '165_bagOfWords_Post','166_bagOfWords_Post','167_bagOfWords_Post','168_bagOfWords_Post',\n",
    "                       '169_bagOfWords_Post','170_bagOfWords_Post','171_bagOfWords_Post','172_bagOfWords_Post',\n",
    "                       '173_bagOfWords_Post','174_bagOfWords_Post','175_bagOfWords_Post','176_bagOfWords_Post',\n",
    "                       '177_bagOfWords_Post','178_bagOfWords_Post','179_bagOfWords_Post','180_bagOfWords_Post',\n",
    "                       '181_bagOfWords_Post','182_bagOfWords_Post','183_bagOfWords_Post','184_bagOfWords_Post',\n",
    "                       '185_bagOfWords_Post','186_bagOfWords_Post','187_bagOfWords_Post','188_bagOfWords_Post',\n",
    "                       '189_bagOfWords_Post','190_bagOfWords_Post','191_bagOfWords_Post','192_bagOfWords_Post',\n",
    "                       '193_bagOfWords_Post','194_bagOfWords_Post','195_bagOfWords_Post','196_bagOfWords_Post',\n",
    "                       '197_bagOfWords_Post','198_bagOfWords_Post','199_bagOfWords_Post','200_bagOfWords_Post',]]\n",
    "pca = PCA(n_components=20)\n",
    "bow_pca = pd.DataFrame(pca.fit_transform(bow_matrix_base))\n",
    "bow_pca_reddit = pd.DataFrame(pca.fit_transform(bow_matrix_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_cols_to_drop = [\"1_bagOfWords_Post\", \"2_bagOfWords_Post\", \"3_bagOfWords_Post\", \"4_bagOfWords_Post\", \n",
    "                       \"5_bagOfWords_Post\", \"6_bagOfWords_Post\",\"7_bagOfWords_Post\",'8_bagOfWords_Post',\n",
    "                       '9_bagOfWords_Post','10_bagOfWords_Post','11_bagOfWords_Post','12_bagOfWords_Post',\n",
    "                       '13_bagOfWords_Post','14_bagOfWords_Post','15_bagOfWords_Post','16_bagOfWords_Post',\n",
    "                       '17_bagOfWords_Post','18_bagOfWords_Post','19_bagOfWords_Post','20_bagOfWords_Post',\n",
    "                       '21_bagOfWords_Post','22_bagOfWords_Post','23_bagOfWords_Post','24_bagOfWords_Post',\n",
    "                       '25_bagOfWords_Post','26_bagOfWords_Post','27_bagOfWords_Post','28_bagOfWords_Post',\n",
    "                       '29_bagOfWords_Post','30_bagOfWords_Post','31_bagOfWords_Post','32_bagOfWords_Post',\n",
    "                       '33_bagOfWords_Post','34_bagOfWords_Post','35_bagOfWords_Post','36_bagOfWords_Post',\n",
    "                       '37_bagOfWords_Post','38_bagOfWords_Post','39_bagOfWords_Post','40_bagOfWords_Post',\n",
    "                       '41_bagOfWords_Post','42_bagOfWords_Post','43_bagOfWords_Post','44_bagOfWords_Post',\n",
    "                       '45_bagOfWords_Post','46_bagOfWords_Post','47_bagOfWords_Post','48_bagOfWords_Post',\n",
    "                       '49_bagOfWords_Post','50_bagOfWords_Post','51_bagOfWords_Post','52_bagOfWords_Post',\n",
    "                       '53_bagOfWords_Post','54_bagOfWords_Post','55_bagOfWords_Post','56_bagOfWords_Post',\n",
    "                       '57_bagOfWords_Post','58_bagOfWords_Post','59_bagOfWords_Post','60_bagOfWords_Post',\n",
    "                       '61_bagOfWords_Post','62_bagOfWords_Post','63_bagOfWords_Post','64_bagOfWords_Post',\n",
    "                       '65_bagOfWords_Post','66_bagOfWords_Post','67_bagOfWords_Post','68_bagOfWords_Post',\n",
    "                       '69_bagOfWords_Post','70_bagOfWords_Post','71_bagOfWords_Post','72_bagOfWords_Post',\n",
    "                       '73_bagOfWords_Post','74_bagOfWords_Post','75_bagOfWords_Post','76_bagOfWords_Post',\n",
    "                       '77_bagOfWords_Post','78_bagOfWords_Post','79_bagOfWords_Post','80_bagOfWords_Post',\n",
    "                       '81_bagOfWords_Post','82_bagOfWords_Post','83_bagOfWords_Post','84_bagOfWords_Post',\n",
    "                       '85_bagOfWords_Post','86_bagOfWords_Post','87_bagOfWords_Post','88_bagOfWords_Post',\n",
    "                       '89_bagOfWords_Post','90_bagOfWords_Post','91_bagOfWords_Post','92_bagOfWords_Post',\n",
    "                       '93_bagOfWords_Post','94_bagOfWords_Post','95_bagOfWords_Post','96_bagOfWords_Post',\n",
    "                       '97_bagOfWords_Post','98_bagOfWords_Post','99_bagOfWords_Post','100_bagOfWords_Post',\n",
    "                       '101_bagOfWords_Post','102_bagOfWords_Post','103_bagOfWords_Post','104_bagOfWords_Post',\n",
    "                       '105_bagOfWords_Post','106_bagOfWords_Post','107_bagOfWords_Post','108_bagOfWords_Post',\n",
    "                       '109_bagOfWords_Post','110_bagOfWords_Post','111_bagOfWords_Post','112_bagOfWords_Post',\n",
    "                       '113_bagOfWords_Post','114_bagOfWords_Post','115_bagOfWords_Post','116_bagOfWords_Post',\n",
    "                       '117_bagOfWords_Post','118_bagOfWords_Post','119_bagOfWords_Post','120_bagOfWords_Post',\n",
    "                       '121_bagOfWords_Post','122_bagOfWords_Post','123_bagOfWords_Post','124_bagOfWords_Post',\n",
    "                       '125_bagOfWords_Post','126_bagOfWords_Post','127_bagOfWords_Post','128_bagOfWords_Post',\n",
    "                       '129_bagOfWords_Post','130_bagOfWords_Post','131_bagOfWords_Post','132_bagOfWords_Post',\n",
    "                       '133_bagOfWords_Post','134_bagOfWords_Post','135_bagOfWords_Post','136_bagOfWords_Post',\n",
    "                       '137_bagOfWords_Post','138_bagOfWords_Post','139_bagOfWords_Post','140_bagOfWords_Post',\n",
    "                       '141_bagOfWords_Post','142_bagOfWords_Post','143_bagOfWords_Post','144_bagOfWords_Post',\n",
    "                       '145_bagOfWords_Post','146_bagOfWords_Post','147_bagOfWords_Post','148_bagOfWords_Post',\n",
    "                       '149_bagOfWords_Post','150_bagOfWords_Post','151_bagOfWords_Post','152_bagOfWords_Post',\n",
    "                       '153_bagOfWords_Post','154_bagOfWords_Post','155_bagOfWords_Post','156_bagOfWords_Post',\n",
    "                       '157_bagOfWords_Post','158_bagOfWords_Post','159_bagOfWords_Post','160_bagOfWords_Post',\n",
    "                       '161_bagOfWords_Post','162_bagOfWords_Post','163_bagOfWords_Post','164_bagOfWords_Post',\n",
    "                       '165_bagOfWords_Post','166_bagOfWords_Post','167_bagOfWords_Post','168_bagOfWords_Post',\n",
    "                       '169_bagOfWords_Post','170_bagOfWords_Post','171_bagOfWords_Post','172_bagOfWords_Post',\n",
    "                       '173_bagOfWords_Post','174_bagOfWords_Post','175_bagOfWords_Post','176_bagOfWords_Post',\n",
    "                       '177_bagOfWords_Post','178_bagOfWords_Post','179_bagOfWords_Post','180_bagOfWords_Post',\n",
    "                       '181_bagOfWords_Post','182_bagOfWords_Post','183_bagOfWords_Post','184_bagOfWords_Post',\n",
    "                       '185_bagOfWords_Post','186_bagOfWords_Post','187_bagOfWords_Post','188_bagOfWords_Post',\n",
    "                       '189_bagOfWords_Post','190_bagOfWords_Post','191_bagOfWords_Post','192_bagOfWords_Post',\n",
    "                       '193_bagOfWords_Post','194_bagOfWords_Post','195_bagOfWords_Post','196_bagOfWords_Post',\n",
    "                       '197_bagOfWords_Post','198_bagOfWords_Post','199_bagOfWords_Post','200_bagOfWords_Post',]\n",
    "\n",
    "X_matrix_reddit = X_matrix_reddit.drop(columns=bow_cols_to_drop)\n",
    "X_matrix_r = X_matrix_r.drop(columns=bow_cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix_reddit = pd.concat([X_matrix_reddit, bow_pca], axis=1)\n",
    "X_matrix_r = pd.concat([X_matrix_r, bow_pca_reddit], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_matrix_reddit, Y_matrix, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_totalcommentsBefore_Source</th>\n",
       "      <th>std_totalcommentsBefore_Source</th>\n",
       "      <th>min_totalcommentsBefore_Source</th>\n",
       "      <th>max_totalcommentsBefore_Source</th>\n",
       "      <th>median_totalcommentsBefore_Source</th>\n",
       "      <th>mean_comments24Before_Source</th>\n",
       "      <th>std_comments24Before_Source</th>\n",
       "      <th>min_comments24Before_Source</th>\n",
       "      <th>max_comments24Before_Source</th>\n",
       "      <th>median_comments24Before_Source</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52392</th>\n",
       "      <td>33.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>15.556349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149762</td>\n",
       "      <td>0.417263</td>\n",
       "      <td>0.123156</td>\n",
       "      <td>-0.082312</td>\n",
       "      <td>-0.527593</td>\n",
       "      <td>-0.746916</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>0.240768</td>\n",
       "      <td>-0.422553</td>\n",
       "      <td>0.397178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52393</th>\n",
       "      <td>33.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>15.556349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149762</td>\n",
       "      <td>0.417263</td>\n",
       "      <td>0.123156</td>\n",
       "      <td>-0.082312</td>\n",
       "      <td>-0.527593</td>\n",
       "      <td>-0.746916</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>0.240768</td>\n",
       "      <td>-0.422553</td>\n",
       "      <td>0.397178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52394</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52395</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52396</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017903</td>\n",
       "      <td>-0.016757</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.014102</td>\n",
       "      <td>-0.015837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52397 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_totalcommentsBefore_Source  std_totalcommentsBefore_Source  \\\n",
       "0                             40.30467                       53.845657   \n",
       "1                             40.30467                       53.845657   \n",
       "2                             40.30467                       53.845657   \n",
       "3                             40.30467                       53.845657   \n",
       "4                             40.30467                       53.845657   \n",
       "...                                ...                             ...   \n",
       "52392                         33.00000                        0.000000   \n",
       "52393                         33.00000                        0.000000   \n",
       "52394                          0.00000                        0.000000   \n",
       "52395                          0.00000                        0.000000   \n",
       "52396                          0.00000                        0.000000   \n",
       "\n",
       "       min_totalcommentsBefore_Source  max_totalcommentsBefore_Source  \\\n",
       "0                                 0.0                           401.0   \n",
       "1                                 0.0                           401.0   \n",
       "2                                 0.0                           401.0   \n",
       "3                                 0.0                           401.0   \n",
       "4                                 0.0                           401.0   \n",
       "...                               ...                             ...   \n",
       "52392                            33.0                            33.0   \n",
       "52393                            33.0                            33.0   \n",
       "52394                             0.0                             0.0   \n",
       "52395                             0.0                             0.0   \n",
       "52396                             0.0                             0.0   \n",
       "\n",
       "       median_totalcommentsBefore_Source  mean_comments24Before_Source  \\\n",
       "0                                   15.0                      15.52416   \n",
       "1                                   15.0                      15.52416   \n",
       "2                                   15.0                      15.52416   \n",
       "3                                   15.0                      15.52416   \n",
       "4                                   15.0                      15.52416   \n",
       "...                                  ...                           ...   \n",
       "52392                               33.0                      11.00000   \n",
       "52393                               33.0                      11.00000   \n",
       "52394                                0.0                       0.00000   \n",
       "52395                                0.0                       0.00000   \n",
       "52396                                0.0                       0.00000   \n",
       "\n",
       "       std_comments24Before_Source  min_comments24Before_Source  \\\n",
       "0                        32.441880                          0.0   \n",
       "1                        32.441880                          0.0   \n",
       "2                        32.441880                          0.0   \n",
       "3                        32.441880                          0.0   \n",
       "4                        32.441880                          0.0   \n",
       "...                            ...                          ...   \n",
       "52392                    15.556349                          0.0   \n",
       "52393                    15.556349                          0.0   \n",
       "52394                     0.000000                          0.0   \n",
       "52395                     0.000000                          0.0   \n",
       "52396                     0.000000                          0.0   \n",
       "\n",
       "       max_comments24Before_Source  median_comments24Before_Source  ...  \\\n",
       "0                            377.0                             3.0  ...   \n",
       "1                            377.0                             3.0  ...   \n",
       "2                            377.0                             3.0  ...   \n",
       "3                            377.0                             3.0  ...   \n",
       "4                            377.0                             3.0  ...   \n",
       "...                            ...                             ...  ...   \n",
       "52392                         33.0                             0.0  ...   \n",
       "52393                         33.0                             0.0  ...   \n",
       "52394                          0.0                             0.0  ...   \n",
       "52395                          0.0                             0.0  ...   \n",
       "52396                          0.0                             0.0  ...   \n",
       "\n",
       "             10        11        12        13        14        15        16  \\\n",
       "0     -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "1     -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "2     -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "3     -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "4     -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "52392 -0.149762  0.417263  0.123156 -0.082312 -0.527593 -0.746916  0.182174   \n",
       "52393 -0.149762  0.417263  0.123156 -0.082312 -0.527593 -0.746916  0.182174   \n",
       "52394 -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "52395 -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "52396 -0.017903 -0.016757 -0.028638 -0.070825 -0.002571 -0.011389 -0.006042   \n",
       "\n",
       "             17        18        19  \n",
       "0      0.011143 -0.014102 -0.015837  \n",
       "1      0.011143 -0.014102 -0.015837  \n",
       "2      0.011143 -0.014102 -0.015837  \n",
       "3      0.011143 -0.014102 -0.015837  \n",
       "4      0.011143 -0.014102 -0.015837  \n",
       "...         ...       ...       ...  \n",
       "52392  0.240768 -0.422553  0.397178  \n",
       "52393  0.240768 -0.422553  0.397178  \n",
       "52394  0.011143 -0.014102 -0.015837  \n",
       "52395  0.011143 -0.014102 -0.015837  \n",
       "52396  0.011143 -0.014102 -0.015837  \n",
       "\n",
       "[52397 rows x 60 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_matrix_reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1062.80\n",
      "Variance score: 0.27\n",
      "Root-mean squared error: 32.60\n"
     ]
    }
   ],
   "source": [
    "lm_pca = LinearRegression()\n",
    "lm_pca.fit(X_train_r, y_train_r)\n",
    "lmPred_pca = lm_pca.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm_pca.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % lm_pca.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, lmPred_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1091464495724825443041280.00\n",
      "Variance score: -436097999049157888.00\n",
      "Root-mean squared error: 1044731781714.73\n"
     ]
    }
   ],
   "source": [
    "lmPred_pca_r = lm_pca.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm_pca.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % lm_pca.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, lmPred_pca_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1111.80\n",
      "Variance score: 0.24\n",
      "Root-mean squared error: 33.34\n"
     ]
    }
   ],
   "source": [
    "KNN_pca = KNeighborsRegressor(n_neighbors=15, weights='uniform') \n",
    "KNN_pca.fit(X_train_r, y_train_r)\n",
    "KNN_pca_pred = KNN_pca.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((KNN_pca.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN_pca.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, KNN_pca_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8690793.40\n",
      "Variance score: -2.47\n",
      "Root-mean squared error: 2948.02\n"
     ]
    }
   ],
   "source": [
    "KNN_pca_Pred_r = KNN_pca.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((KNN_pca.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN_pca.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, KNN_pca_Pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 948.58\n",
      "Variance score: 0.35\n",
      "Root-mean squared error: 30.80\n"
     ]
    }
   ],
   "source": [
    "xgb_pca = XGBRegressor()\n",
    "xgb_pca.fit(X_train_r, y_train_r)\n",
    "xgb_Pred_pca = xgb_pca.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((xgb_pca.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb_pca.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, xgb_Pred_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8787181.58\n",
      "Variance score: -2.51\n",
      "Root-mean squared error: 2964.32\n"
     ]
    }
   ],
   "source": [
    "xgb_Pred_r_pca = xgb_pca.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((xgb_pca.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb_pca.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, xgb_Pred_r_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1110.46\n",
      "Variance score: 0.24\n",
      "Root-mean squared error: 33.32\n"
     ]
    }
   ],
   "source": [
    "rf_reg_pca = RandomForestRegressor() \n",
    "rf_reg_pca.fit(X_train_r, y_train_r)\n",
    "rf_reg_pred_pca = rf_reg_pca.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((rf_reg_pca.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg_pca.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, rf_reg_pred_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8251487.48\n",
      "Variance score: -2.30\n",
      "Root-mean squared error: 2872.54\n"
     ]
    }
   ],
   "source": [
    "rf_reg_pred_r_pca = rf_reg_pca.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((rf_reg_pca.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg_pca.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, rf_reg_pred_r_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1607.64\n",
      "Variance score: -0.10\n",
      "Root-mean squared error: 40.10\n"
     ]
    }
   ],
   "source": [
    "dt_pca = DecisionTreeRegressor() \n",
    "dt_pca.fit(X_train_r, y_train_r)\n",
    "dt_pred_pca = dt_pca.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((dt_pca.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % dt_pca.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, dt_pred_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8815038.22\n",
      "Variance score: -2.52\n",
      "Root-mean squared error: 2969.01\n"
     ]
    }
   ],
   "source": [
    "dt_pred_r_pca = dt_pca.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((dt_pca.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % dt_pca.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, dt_pred_r_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1067.68\n",
      "Variance score: 0.27\n",
      "Root-mean squared error: 32.68\n"
     ]
    }
   ],
   "source": [
    "gb_pca = GradientBoostingRegressor()\n",
    "gb_pca.fit(X_train_r, y_train_r)\n",
    "gb_pred_pca = gb_pca.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((gb_pca.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % gb_pca.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, gb_pred_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8587161.40\n",
      "Variance score: -2.43\n",
      "Root-mean squared error: 2930.39\n"
     ]
    }
   ],
   "source": [
    "gb_pred_r_pca = gb_pca.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((gb_pca.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % gb_pca.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, gb_pred_r_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove constant cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_val_columns = [\"mean_totalcommentsBefore_Source\", \"std_totalcommentsBefore_Source\", \n",
    "                        \"min_totalcommentsBefore_Source\", \"max_totalcommentsBefore_Source\", \n",
    "                        \"median_totalcommentsBefore_Source\", \"mean_comments24Before_Source\", \n",
    "                        \"std_comments24Before_Source\", \"min_comments24Before_Source\", \n",
    "                        \"max_comments24Before_Source\", \"median_comments24Before_Source\", \n",
    "                        \"mean_commentsIntervalBefore_Source\", \"std_commentsIntervalBefore_Source\", \n",
    "                        \"min_commentsIntervalBefore_Source\", \"max_commentsIntervalBefore_Source\", \n",
    "                        \"median_commentsIntervalBefore_Source\", \"mean_comments24After_Source\", \n",
    "                        \"std_comments24After_Source\", \"min_comments24After_Source\", \n",
    "                        \"max_comments24After_Source\", \"median_comments24After_Source\",\n",
    "                        \"mean_comments24Interval_Source\", \"std_comments24Interval_Source\", \n",
    "                        \"min_comments24Interval_Source\", \"max_comments24Interval_Source\", \n",
    "                        \"median_comments24Interval_Source\"]\n",
    "                        \n",
    "\n",
    "X_matrix_reddit = X_matrix_reddit.drop(columns=constant_val_columns)\n",
    "X_matrix_r = X_matrix_r.drop(columns=constant_val_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_matrix_reddit, Y_matrix, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1915612871503.81\n",
      "Variance score: -1278785599.43\n",
      "Root-mean squared error: 1384056.67\n"
     ]
    }
   ],
   "source": [
    "lm_stats = LinearRegression()\n",
    "lm_stats.fit(X_train_r, y_train_r)\n",
    "lmPred_stats = lm_stats.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm_stats.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % lm_stats.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, lmPred_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 5773326198070741.00\n",
      "Variance score: -2306750253.08\n",
      "Root-mean squared error: 75982407.16\n"
     ]
    }
   ],
   "source": [
    "lmPred_stats_r = lm_stats.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((lm_stats.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % lm_stats.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, lmPred_stats_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1533.73\n",
      "Variance score: -0.02\n",
      "Root-mean squared error: 39.16\n"
     ]
    }
   ],
   "source": [
    "KNN_stats = KNeighborsRegressor(n_neighbors=15, weights='uniform') \n",
    "KNN_stats.fit(X_train_r, y_train_r)\n",
    "KNN_stats_pred = KNN_stats.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((KNN_stats.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN_stats.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, KNN_stats_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 9162992.89\n",
      "Variance score: -2.66\n",
      "Root-mean squared error: 3027.04\n"
     ]
    }
   ],
   "source": [
    "KNN_stats_Pred_r = KNN_stats.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((KNN_stats.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % KNN_stats.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, KNN_stats_Pred_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1415.65\n",
      "Variance score: 0.05\n",
      "Root-mean squared error: 37.63\n"
     ]
    }
   ],
   "source": [
    "xgb_stats = XGBRegressor()\n",
    "xgb_stats.fit(X_train_r, y_train_r)\n",
    "xgb_Pred_stats = xgb_stats.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((xgb_stats.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb_stats.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, xgb_Pred_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8617840.39\n",
      "Variance score: -2.44\n",
      "Root-mean squared error: 2935.62\n"
     ]
    }
   ],
   "source": [
    "xgb_Pred_r_stats = xgb_stats.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((xgb_stats.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % xgb_stats.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, xgb_Pred_r_stats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1374.65\n",
      "Variance score: 0.08\n",
      "Root-mean squared error: 37.08\n"
     ]
    }
   ],
   "source": [
    "rf_reg_stats = RandomForestRegressor() \n",
    "rf_reg_stats.fit(X_train_r, y_train_r)\n",
    "rf_reg_pred_stats = rf_reg_stats.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((rf_reg_stats.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg_stats.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, rf_reg_pred_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8683012.85\n",
      "Variance score: -2.47\n",
      "Root-mean squared error: 2946.70\n"
     ]
    }
   ],
   "source": [
    "rf_reg_pred_r_stats = rf_reg_stats.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((rf_reg_stats.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % rf_reg_stats.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, rf_reg_pred_r_stats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 2311.84\n",
      "Variance score: -0.54\n",
      "Root-mean squared error: 48.08\n"
     ]
    }
   ],
   "source": [
    "dt_stats = DecisionTreeRegressor() \n",
    "dt_stats.fit(X_train_r, y_train_r)\n",
    "dt_pred_stats = dt_stats.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((dt_stats.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % dt_stats.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, dt_pred_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8797524.88\n",
      "Variance score: -2.52\n",
      "Root-mean squared error: 2966.06\n"
     ]
    }
   ],
   "source": [
    "dt_pred_r_stats = dt_stats.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((dt_stats.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % dt_stats.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, dt_pred_r_stats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Stats Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1448.45\n",
      "Variance score: 0.03\n",
      "Root-mean squared error: 38.06\n"
     ]
    }
   ],
   "source": [
    "gb_stats = GradientBoostingRegressor()\n",
    "gb_stats.fit(X_train_r, y_train_r)\n",
    "gb_pred_stats = gb_stats.predict(X_test_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((gb_stats.predict(X_test_r) - y_test_r) ** 2))\n",
    "print('Variance score: %.2f' % gb_stats.score(X_test_r, y_test_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test_r, gb_pred_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 8845325.39\n",
      "Variance score: -2.53\n",
      "Root-mean squared error: 2974.11\n"
     ]
    }
   ],
   "source": [
    "gb_pred_r_stats = gb_stats.predict(X_matrix_r)\n",
    "\n",
    "print(\"Residual sum of squares: %.2f\" % np.mean((gb_stats.predict(X_matrix_r) - Y_matrix_r) ** 2))\n",
    "print('Variance score: %.2f' % gb_stats.score(X_matrix_r, Y_matrix_r))\n",
    "print('Root-mean squared error: %.2f' % np.sqrt(metrics.mean_squared_error(Y_matrix_r, gb_pred_r_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
